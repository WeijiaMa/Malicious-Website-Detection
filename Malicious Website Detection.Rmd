---
title: "Final Project"
author: "Weijia Ma and Rosa Zhu"
date: "5/17/2018"
output:
  html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
set.seed(1)
library(ggformula)
library(gridExtra)
library(broom)
library(dplyr)
library(tidyr)
library(stringr)
library(car)
library(GGally)
library(pander)
library(purrr)
library(MASS)
library(effects)
library(ROCR)
```



# Load Dataset
```{r}
website <- read.csv("~/Desktop/Malicious-Website-Detection/benign_or_malicious_website.csv")
```


# Data Wrangling and Cleaning

We find that the dataset is not cleaned for analysis yet, so we did data wrangling and cleaning first. We turned all character data to uppercase, removed the less useful variable and id varaible. We also combined some levels of the categorical variables server and country because they have too many (>20) levels to conduct intepretation. We kept "NONE" as a level to indicate unavailable information because it might mean that the information could not be fetched by the researcher due to the covert nature of the website.

We also transformed the registration date from server response to be the number of days it is away from the first registration date in the dataset, and we added a indicator variable for whether the registration date is unknown (1 for unknown, and 0 for known). We performed the same transformation on the updated date from server response.

```{r}
# upper case
website <- website %>% mutate_if(is.factor, toupper)
website <- website %>% mutate_if(is.character, as.factor)
# omitting NA values in the dataset
website <- na.omit(website)
# getting rid of WHOIS_STATEPRO and URL
website <- website %>% 
  dplyr::select(-c(WHOIS_STATEPRO, URL))
# simplify SERVER
website <- website %>% 
  mutate(SERVER = str_replace_all(SERVER, pattern = "APACHE.*", "APACHE")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "MICROSOFT.*", "MICROSOFT")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "ATS.*", "ATS")) %>%
  mutate(SERVER = str_replace_all(SERVER, pattern = "NGINX.*", "NGINX")) %>%
  mutate(SERVER = factor(SERVER))
# main SERVER
main.server <- c("APACHE", "GSE", "MICROSOFT", "NGINX", "NONE")
# wrong SERVER
wrong.server <- c("XXXXXXXXXXXXXXXXXXXXXX", "YIPPEE-KI-YAY", "WWW.LEXISNEXIS.COM  9999", "SERVER")
# combine wrong and main SERVER
server.comb <- combine(main.server, wrong.server)
# simplify SERVER, all values not in main server or wrong server lists are set to be "OTHER", 
# values in wrong server lists are set to be "SUSPICIOUS"
website <- website %>% 
  mutate(SERVER = as.factor(ifelse(SERVER %in% server.comb, as.character(SERVER), "OTHER"))) %>%
  mutate(SERVER = as.factor(ifelse(SERVER %in% wrong.server, "SUSPICIOUS", as.character(SERVER))))
# simplify WHOIS_COUNTRY
website <- website %>% 
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, ".*UK.*", "UK")) %>%
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, "UNITED KINGDOM", "UK")) %>%
  mutate(WHOIS_COUNTRY = str_replace_all(WHOIS_COUNTRY, "GB", "UK")) %>%
  mutate(WHOIS_COUNTRY = factor(WHOIS_COUNTRY))
main.country <- c("UK", "US", "CA", "NONE")
website <- website %>% 
  mutate(WHOIS_COUNTRY = as.factor(ifelse(WHOIS_COUNTRY %in% main.country, as.character(WHOIS_COUNTRY), "OTHER"))) %>%
  mutate(WHOIS_COUNTRY = relevel(WHOIS_COUNTRY, ref = "NONE"))
# simplify CHARSET
website <- website %>% 
  mutate(CHARSET = str_replace_all(CHARSET, pattern = "ISO-8859.*", "ISO-8859")) %>%
  mutate(CHARSET = str_replace_all(CHARSET, pattern = "WINDOWS.*", "WINDOWS")) %>%
  mutate(CHARSET = as.factor(CHARSET))
# simplify WHOIS_REGDATE
website <- website %>%
  mutate(WHOIS_REGDATE = as.Date(WHOIS_REGDATE, format = ifelse(grepl("T", as.Date(WHOIS_REGDATE)), "%Y-%m-%dT", "%d/%m/%Y"))) %>% 
  mutate(WHOIS_REGDATE = as.numeric(difftime(WHOIS_REGDATE, as.Date("1990-07-26"), units = "days"))) %>%
  mutate(NA_REGDATE = as.factor(ifelse(is.na(WHOIS_REGDATE), 1, 0))) 
mean.reg.date <- mean(website$WHOIS_REGDATE, na.rm = TRUE)
website <- website %>%
  mutate(WHOIS_REGDATE = ifelse(is.na(WHOIS_REGDATE), mean.reg.date, WHOIS_REGDATE))
# simplify WHOIS_UPDATED_DATE
website <- website %>%
  mutate(WHOIS_UPDATED_DATE = as.Date(WHOIS_UPDATED_DATE, format = ifelse(grepl("T", WHOIS_UPDATED_DATE), "%Y-%m-%dT", "%d/%m/%Y"))) %>%
  mutate(WHOIS_UPDATED_DATE = as.numeric(difftime(WHOIS_UPDATED_DATE, as.Date("2008-07-14"), units = "days"))) %>%
  mutate(NA_UPDATED_DATE = as.factor(ifelse(is.na(WHOIS_UPDATED_DATE), 1, 0)))
mean.update.date <- mean(na.omit(website$WHOIS_UPDATED_DATE))
website <- website %>%
  mutate(WHOIS_UPDATED_DATE = ifelse(is.na(WHOIS_UPDATED_DATE), mean.update.date, WHOIS_UPDATED_DATE))
# factor Type
website <- website %>% mutate(Type = as.factor(Type))
website.sm <- website %>%
  mutate(WHOIS_REGDATE = ifelse(is.na(WHOIS_REGDATE), mean.reg.date, WHOIS_REGDATE))
```
  
# EDA

```{r}
# App Packets & Bytes
ggpairs(website[, 12:17])
gf_boxplot(APP_BYTES ~ Type, data = website)
gf_boxplot(URL_LENGTH ~ Type, data = website)
gf_boxplot(DNS_QUERY_TIMES ~ Type, data = website)

# Quantatative
# select quantitative vars
website.quant <- website %>% 
  dplyr::select(-c(SERVER, WHOIS_COUNTRY, CHARSET))
website.quant %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_histogram()

# Charset
website %>% gf_bar(~CHARSET, fill=~Type)
table(website$CHARSET, website$Type) %>% prop.table(margin=1)

# SERVER
website %>% gf_bar(~SERVER, fill=~Type)
table(website$SERVER, website$Type) %>% prop.table(margin=1)

# REGDATE
gf_boxplot(WHOIS_REGDATE ~ Type, data = website)

# numerical summary of the data
web.sum <- summary(website)
pander(web.sum)

# graphical summary of the data (some variables)
spineplot(Type ~ SERVER, data = website)
spineplot(Type ~ WHOIS_COUNTRY, data = website)
```

# Fit Model for Inference
## Fit Full Model
```{r}
inf.mod.full <- glm(Type ~ . , data = website, family = binomial)
str(website)
summary(inf.mod.full)
# Outlier Detection and elimination
influenceIndexPlot(inf.mod.full, vars = c("Cook", "Studentized", "hat"))
residualPlots(inf.mod.full)
website <- website [-c(443,898,468,897,671,72,558),]
inf.mod.no.outlier <- glm(Type ~ . , data = website, family = binomial)
influenceIndexPlot(inf.mod.no.outlier, vars = c("Cook", "Studentized", "hat"))
# Assumption Checking
residualPlots(inf.mod.no.outlier)
```

We fit the full model of log odds of malicious website on all the variables. Through repeated influential point detection, we found 7 outliers with high Cook's Distance and/or Standardized Redisual so they are excluded from the rest of the analysis.

Assumption checking tells us that the linearity assumption is satisfied.

## Model Selection

We first eliminate the multicollinear terms found during EDA. Then, we conducted stepwise selection based on AIC. 

```{r fig.height=9, fig.width=12}
# Multicollinearity (PACKETS & BYTES)
inf.mod.bytes <- update(inf.mod.no.outlier, . ~ . - (REMOTE_APP_PACKETS + SOURCE_APP_PACKETS +  REMOTE_APP_BYTES + APP_PACKETS + APP_BYTES))
anova(inf.mod.bytes, inf.mod.no.outlier, test = "Chisq")
# Stepwise selection
inf.mod.aic <- stepAIC(inf.mod.bytes,
                       scope = list(lower ~ 1),
                       direction = "both",
                       trace = 0)
pander(tidy(inf.mod.aic))
# Drop in deviance test for server and country
inf.mod.country <- update(inf.mod.aic, . ~ . + WHOIS_COUNTRY)
anova(inf.mod.aic, inf.mod.country, test = "Chisq")
inf.mod.server <- update(inf.mod.aic, . ~ . + SERVER)
anova(inf.mod.aic, inf.mod.server, test = "Chisq")
```

We see that although certain levels in server and country are insignificant according to the Wald test, we see that at least one of the coefficient is not 0 according to the drop-in-deviance tests.

# Model assessment
```{r}
# Check for linearity & outliers
influenceIndexPlot(inf.mod.aic, vars = c("Cook", "Studentized", "hat"))
crPlots(inf.mod.aic)
# Check for overdispersion
1 - pchisq(209.45, 952)
inf.mod.aic$deviance/inf.mod.aic$df.residual
# Visualize the model
plot(allEffects(inf.mod.aic, title=""), rows = 3, cols = 4, main="")
```

There doesn't seem to be any outliers or non-linearity. The large p-value of the goodness of fit test and the small dispersion parameter (0.22) indicates that the model is adequate and that overdispersion is not likely to be present.

## Interpretation
```{r}
pander(100*exp(coef(inf.mod.aic)))
```

# Fit Model for Prediction

## Create Training and Test Datasets
```{r}
index <- sample(1:nrow(website), size=0.2*nrow(website))
website.train <- website[-index, ]
website.test <- website[index, ]
```

## Fit Model
```{r}
# Full model
pred.mod.full <- glm(Type ~ . , data = website.train, family = binomial)
summary(pred.mod.full)

# No packets
pred.mod.no.packet <- glm(Type ~ . -(REMOTE_APP_PACKETS + SOURCE_APP_PACKETS +  REMOTE_APP_BYTES + APP_PACKETS + APP_BYTES), data = website.train, family = binomial)
summary(pred.mod.no.packet)

# Avoid overfitting, use the reduced model we got from AIC stepwise elimination
pred.mod.inf.mod.aic <- update(inf.mod.aic, Type ~ URL_LENGTH + NUMBER_SPECIAL_CHARACTERS + SERVER + CONTENT_LENGTH +
                                 WHOIS_COUNTRY + WHOIS_REGDATE + TCP_CONVERSATION_EXCHANGE + DIST_REMOTE_TCP_PORT +
                                 SOURCE_APP_BYTES + DNS_QUERY_TIMES + NA_UPDATED_DATE, data = website.train, family = binomial)
summary(pred.mod.inf.mod.aic)

# No server
pred.mod.no.server <- update(pred.mod.no.packet, . ~ . -SERVER, data = website.train, family = binomial)
summary(pred.mod.no.server)

# No country
pred.mod.no.country <- update(pred.mod.no.packet, . ~ . -WHOIS_COUNTRY, data = website.train, family = binomial)
summary(pred.mod.no.country)

# No update date
pred.mod.final <- update(pred.mod.no.packet, . ~ . -WHOIS_UPDATED_DATE, data = website.train, family = binomial)
summary(pred.mod.final)
```

## Prediction
```{r}
# With full model
pred.full.col <- predict(pred.mod.full, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.full = as.factor(ifelse(as.numeric(pred.full.col) <= 0.5, 0, 1)))
(accuracy.full <- mean(website.test$pred.full == website.test$Type))

# With no packet model
pred.no.packet.col <- predict(pred.mod.no.packet, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.packet = as.factor(ifelse(as.numeric(pred.no.packet.col) <= 0.5, 0, 1)))
(accuracy.no.packet <- mean(website.test$pred.no.packet == website.test$Type))

# With inf.mod.aic model
pred.inf.mod.aic.col <- predict(pred.mod.inf.mod.aic, newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.inf.mod.aic = as.factor(ifelse(as.numeric(pred.inf.mod.aic.col) <= 0.5, 0, 1)))
(accuracy.inf.mod.aic <- mean(website.test$pred.inf.mod.aic == website.test$Type))

# With no server model
pred.no.server.col  <- predict(pred.mod.no.server , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.server = as.factor(ifelse(as.numeric(pred.no.server.col) <= 0.5, 0, 1)))
(accuracy.no.server <- mean(website.test$pred.no.server == website.test$Type))

# With no country model
pred.no.country.col  <- predict(pred.mod.no.country , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.no.country = as.factor(ifelse(as.numeric(pred.no.country.col) <= 0.5, 0, 1)))
(accuracy.no.country  <- mean(website.test$pred.no.country  == website.test$Type))

# No DNS
pred.final.col <- predict(pred.mod.final , newdata = website.test, type = "response")
website.test <- website.test %>% mutate(pred.final = as.factor(ifelse(as.numeric(pred.final.col) <= 0.5, 0, 1)))
(accuracy.final  <- mean(website.test$pred.final  == website.test$Type))
```

```{r}
pred.final.sum <- summary(pred.mod.final)
pander(cbind(pred.final.sum$coefficients), type = "pdf")

preds_obj2 <- prediction(pred.inf.mod.aic.col, website.test$Type)
perf_obj2 <- performance(preds_obj2, "tpr","fpr")
perf_df2 <- data_frame(fpr=unlist(perf_obj2@x.values),tpr= unlist(perf_obj2@y.values), threshold=unlist(perf_obj2@alpha.values), model="Inferential Model")
plot(perf_obj2)

preds_obj1 <- prediction(pred.final.col, website.test$Type)
perf_obj1 <- performance(preds_obj1, "tpr","fpr")
perf_df1 <- data_frame(fpr=unlist(perf_obj1@x.values),tpr= unlist(perf_obj1@y.values), threshold=unlist(perf_obj1@alpha.values), model="Predictive Model")
head(perf_df1)
perf_df <- bind_rows(perf_df1, perf_df2)
perf_df
ggplot(perf_df, aes(x=fpr, y=tpr, color=model)) +  geom_line() + 
  labs(x="false positive rate (1-specificity)", y="true positive rate (sensitivity)", title="ROC curve for logistic") + 
  geom_abline(slope=1,intercept=0, linetype=3) 

ggplot(perf_df1, aes(x=fpr, y=tpr, color=threshold)) +  geom_line() + 
  labs(x="false positive rate (1-specificity)", y="true positive rate (sensitivity)", title="ROC curve for logistic") + 
  geom_abline(slope=1,intercept=0, linetype=3) + 
  scale_color_gradient2(midpoint=0.5, mid="black", low="orange", high="pink")
```

